{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25514e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac7eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/ml-100k/\"\n",
    "\n",
    "names = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "df = pd.read_csv(os.path.join(DATA_PATH, \"u.data\"), sep='\\t', names=names)\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "\n",
    "ratings = np.zeros((n_users, n_items))\n",
    "for _, row in df.iterrows():\n",
    "    ratings[row.user_id - 1, row.item_id - 1] = row.rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660614f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings: np.ndarray):\n",
    "    test = np.zeros(ratings.shape)\n",
    "    train = ratings.copy()\n",
    "    for user in range(ratings.shape[0]):\n",
    "        test_ratings = np.random.choice(ratings[user, :].nonzero()[0], size=10, replace=False)\n",
    "        train[user, test_ratings] = 0\n",
    "        test[user, test_ratings] = ratings[user, test_ratings]\n",
    "        \n",
    "    assert np.all((train * test) == 0)\n",
    "    return train, test\n",
    "\n",
    "train, test = train_test_split(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "00001bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(predictions, ground_truth):\n",
    "    predictions = predictions[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return np.mean((predictions - ground_truth) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c36f7",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e792b65",
   "metadata": {},
   "source": [
    "The loss function for ALS is\n",
    "$$\n",
    "    L=\\sum_{(i,j)\\in R} (r_{ij}-x_i^Ty_j)^2 + \\lambda_x \\sum_{i} \\lVert x_i \\rVert^2 + \\lambda_y \\sum_{j} \\lVert y_j \\lVert^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee54ce7",
   "metadata": {},
   "source": [
    "Let's give random values to $X$ and $Y$ matrices and fix $X$ matrix first. Then, we can optimize all vectors $y_j$ independently from each other:  \n",
    "\n",
    "$$\n",
    "    \\arg \\min_{y_j} \\sum_{(i,j)\\in R} (r_{ij}-x_i^Ty_j)^2 + \\lambda_x \\sum_{i} \\lVert x_i \\rVert^2 + \\lambda_y \\lVert y_j \\lVert^2 = \\arg\\min_{y_{j}}\\sum _{( i,j) \\in R} r_{ij}^{2} -2\\sum _{( i,j) \\in R} r_{ij} x_{i}^{T} y_{j} +\\sum _{( i,j) \\in R}\\left( x_{i}^{T} y_{j}\\right)^{2} +\\lambda _{y}\\Vert y_{j}\\Vert ^{2} =\\\\\n",
    "    \\arg\\min_{y_{j}} -2\\left(\\sum _{( i,j) \\in R} r_{ij} x_{i}^{T}\\right) y_{j} +\\sum _{( i,j) \\in R} y_{j}^{T} x_{i} x_{i}^{T} y_{j} +\\lambda _{y} y_{j}^{T} y_{j} = \\arg\\min_{y_{j}} -2\\left(\\sum _{( i,j) \\in R} r_{ij} x_{i}^{T}\\right) y_{j} +y_{j}^{T}\\left(\\sum _{( i,j) \\in R} x_{i} x_{i}^{T} +\\lambda _{y}\\right) y_{j}\\\\ \n",
    "    \\Rightarrow y_{j} =\\left(\\sum _{( i,j) \\in R} x_{i} x_{i}^{T} +\\lambda _{y}\\right)^{-1}\\left(\\sum _{( i,j) \\in R} r_{ij} x_{i}\\right)\n",
    "$$  \n",
    "So, the final step solution for $Y$ is:\n",
    "$$\n",
    "    Y = R^TX(A + \\lambda_y)^{-1},\n",
    "$$\n",
    "where $A = \\{a_{ij}\\}_{i,j=1}^k,\\ a_{ij}=\\sum_{k=1}^{N}x_{ki}x_{kj}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d1c57a",
   "metadata": {},
   "source": [
    "When we fix $Y$ matrix, formula for $X$ will be:  \n",
    "$$\n",
    "     \\arg \\min_{x_i} \\sum_{(i,j)\\in R} (r_{ij}-x_i^Ty_j)^2 + \\lambda_x \\lVert x_i \\rVert^2 + \\lambda_y \\sum_{j} \\lVert y_j \\lVert^2 = \\arg\\min_{x_{i}}\\sum _{( i,j) \\in R} r_{ij}^{2} -2\\sum _{( i,j) \\in R} r_{ij} x_{i}^{T} y_{j} +\\sum _{( i,j) \\in R}\\left( x_{i}^{T} y_{j}\\right)^{2} +\\lambda _{x}\\Vert x_{i}\\Vert ^{2} =\\\\\n",
    "    \\arg\\min_{x_{i}} -2 x_{i}^{T}\\left(\\sum _{( i,j) \\in R} r_{ij} y_{j}\\right) +\\sum _{( i,j) \\in R} x_{i}^{T} y_{j} y_{j}^{T} x_{i} +\\lambda _{x} x_{i}^{T} x_{i} = \\arg\\min_{y_{j}} -2x_{i}^{T}\\left(\\sum _{( i,j) \\in R} r_{ij}y_{j}\\right) +x_{i}^{T}\\left(\\sum _{( i,j) \\in R} y_{j} y_{j}^{T} +\\lambda _{x}\\right) x_{i}\\\\ \n",
    "    \\Rightarrow x_{i} =\\left(\\sum _{( i,j) \\in R} y_{j} y_{j}^{T} +\\lambda _{x}\\right)^{-1}\\left(\\sum _{( i,j) \\in R} r_{ij} y_{j}\\right)\n",
    "$$\n",
    "So, the final step solution for $Y$ is:\n",
    "$$\n",
    "    X = RY(A + \\lambda_x)^{-1},\n",
    "$$\n",
    "where $A = \\{a_{ij}\\}_{i,j=1}^k,\\ a_{ij}=\\sum_{k=1}^{M}y_{ki}y_{kj}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0443c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS:\n",
    "    def __init__(self,\n",
    "                 hidden_size: int = 40,\n",
    "                 lambda_x: float = 10,\n",
    "                 lambda_y: float = 10):\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lambda_x = lambda_x\n",
    "        self.lambda_y = lambda_y\n",
    "        \n",
    "    def _compute_loss(self, ratings: np.ndarray):\n",
    "        nonzero_items = ratings.nonzero()\n",
    "        \n",
    "        main_term = np.sum((ratings[nonzero_items] - np.dot(self.X, self.Y.T)[nonzero_items]) ** 2)\n",
    "        user_regularization = self.lambda_x * np.sum(np.linalg.norm(self.X, axis=-1))\n",
    "        item_regularization = self.lambda_y * np.sum(np.linalg.norm(self.Y, axis=-1))\n",
    "        \n",
    "        return main_term + user_regularization + item_regularization\n",
    "        \n",
    "    def _step(self, ratings: np.ndarray, stage: str):\n",
    "        if stage == \"item\":\n",
    "            inverse_matrix = np.linalg.inv(np.einsum(\"ij,ik->jk\", self.X, self.X) + self.lambda_y)\n",
    "            RTX = ratings.T.dot(self.X)\n",
    "            \n",
    "            self.Y = RTX.dot(inverse_matrix)\n",
    "        elif stage == \"user\":\n",
    "            inverse_matrix = np.linalg.inv(np.einsum(\"ij,ik->jk\", self.Y, self.Y) + self.lambda_x)\n",
    "            RY = ratings.dot(self.Y)\n",
    "            \n",
    "            self.X = RY.dot(inverse_matrix)\n",
    "        else:\n",
    "            assert False, \"Invalid stage name!\"\n",
    "        \n",
    "            \n",
    "    def _train_step(self, train_ratings: np.ndarray):\n",
    "        self._step(train_ratings, \"item\")\n",
    "        self._step(train_ratings, \"user\")\n",
    "\n",
    "        loss = self._compute_loss(train_ratings)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def _validation_step(self, val_ratings: np.ndarray):\n",
    "        loss = self._compute_loss(val_ratings)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def fit(self, \n",
    "            train_ratings: np.ndarray, \n",
    "            val_ratings: np.ndarray, \n",
    "            n_epochs: int = 20,\n",
    "            metric_function = None,\n",
    "            verbose=True):\n",
    "        \n",
    "        self.X = np.random.randn(ratings.shape[0], self.hidden_size)\n",
    "        self.Y = np.random.randn(ratings.shape[1], self.hidden_size)\n",
    "        \n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss = self._train_step(train_ratings)\n",
    "            val_loss = self._validation_step(val_ratings)\n",
    "            \n",
    "            print(f\"+--------\\t----------\\t-------+\")\n",
    "            print(f\"|--------\\t EPOCH: {epoch + 1}\\t-------|\")\n",
    "            print(f\"+--------\\t----------\\t-------+\")\n",
    "            if metric_function is not None:\n",
    "                all_predictions = self.predict_all()\n",
    "                \n",
    "                train_metric = metric_function(all_predictions, train_ratings)\n",
    "                val_metric = metric_function(all_predictions, val_ratings)\n",
    "                \n",
    "                print(f\"Train metric: {train_metric}\\t\\tValidation metric: {val_metric}\")\n",
    "            \n",
    "            print(f\"Train loss: {train_loss}\\t\\tValidation loss: {val_loss}\")\n",
    "            \n",
    "    def predict(self, user: int, item: int):\n",
    "        return self.X[user].dot(self.Y[item])\n",
    "    \n",
    "    def predict_all(self):\n",
    "        return self.X.dot(self.Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a128d5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 1\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 5.52133941727585\t\tValidation metric: 9.725381374143891\n",
      "Train loss: 618865.972851474\t\tValidation loss: 210508.60818697713\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 2\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 4.241355928593501\t\tValidation metric: 8.640423970366813\n",
      "Train loss: 508433.4294351986\t\tValidation loss: 205773.02102304422\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 3\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 4.081615556758799\t\tValidation metric: 8.538820734781014\n",
      "Train loss: 495423.53256258206\t\tValidation loss: 206272.6911159226\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 4\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 4.026706951309441\t\tValidation metric: 8.5033806005291\n",
      "Train loss: 491044.99270804966\t\tValidation loss: 206533.02319094303\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 5\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 4.001647848952175\t\tValidation metric: 8.485176083694702\n",
      "Train loss: 489060.4320049387\t\tValidation loss: 206646.39679458117\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 6\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9882655897762076\t\tValidation metric: 8.473623554097317\n",
      "Train loss: 487996.7409741823\t\tValidation loss: 206685.79662328886\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 7\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9804018223286257\t\tValidation metric: 8.466004606964194\n",
      "Train loss: 487365.69712219294\t\tValidation loss: 206695.12751756163\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 8\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.97548042292137\t\tValidation metric: 8.461130341569985\n",
      "Train loss: 486965.9509706278\t\tValidation loss: 206695.14818764426\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 9\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.972243595268751\t\tValidation metric: 8.458111277969946\n",
      "Train loss: 486699.3051960554\t\tValidation loss: 206693.19212382115\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 10\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9700183902135007\t\tValidation metric: 8.456262891345348\n",
      "Train loss: 486512.98179092264\t\tValidation loss: 206690.97525467246\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 11\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.968425201864104\t\tValidation metric: 8.455109007891958\n",
      "Train loss: 486377.0876200701\t\tValidation loss: 206688.4950316593\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 12\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9672411024007683\t\tValidation metric: 8.454346043379404\n",
      "Train loss: 486274.03017149155\t\tValidation loss: 206685.4867161218\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 13\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.966330075120225\t\tValidation metric: 8.453792414227856\n",
      "Train loss: 486193.06949753227\t\tValidation loss: 206681.8170600622\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 14\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9656060588206747\t\tValidation metric: 8.45334477036737\n",
      "Train loss: 486127.41315488255\t\tValidation loss: 206677.5135920583\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 15\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.96501287101552\t\tValidation metric: 8.452946818816814\n",
      "Train loss: 486072.63098367525\t\tValidation loss: 206672.70375724218\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 16\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.964512959738993\t\tValidation metric: 8.452569231742496\n",
      "Train loss: 486025.76409552584\t\tValidation loss: 206667.5531872969\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 17\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9640808415048236\t\tValidation metric: 8.452197487016697\n",
      "Train loss: 485984.80388212454\t\tValidation loss: 206662.22436960018\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 18\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9636990893453423\t\tValidation metric: 8.451824863142987\n",
      "Train loss: 485948.373249888\t\tValidation loss: 206656.85518731872\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 19\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9633557635256245\t\tValidation metric: 8.451448590130155\n",
      "Train loss: 485915.52277912584\t\tValidation loss: 206651.5514815374\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 20\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.963042700325859\t\tValidation metric: 8.451067841975561\n",
      "Train loss: 485885.59548478754\t\tValidation loss: 206646.387866104\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 21\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.962754339164298\t\tValidation metric: 8.450682752492161\n",
      "Train loss: 485858.13467606186\t\tValidation loss: 206641.41253395248\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 22\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9624869041019157\t\tValidation metric: 8.450293967524297\n",
      "Train loss: 485832.8201430724\t\tValidation loss: 206636.65335231603\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 23\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9622378276220642\t\tValidation metric: 8.449902456796037\n",
      "Train loss: 485809.4236256895\t\tValidation loss: 206632.12374554577\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 24\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.962005344578346\t\tValidation metric: 8.449509436420891\n",
      "Train loss: 485787.7777383792\t\tValidation loss: 206627.82766536743\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 25\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.961788207817573\t\tValidation metric: 8.449116327583695\n",
      "Train loss: 485767.7544409067\t\tValidation loss: 206623.7634279833\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 26\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.961585491695578\t\tValidation metric: 8.4487247183737\n",
      "Train loss: 485749.2503437536\t\tValidation loss: 206619.9264551491\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 27\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9613964592762563\t\tValidation metric: 8.44833631758877\n",
      "Train loss: 485732.1769175933\t\tValidation loss: 206616.31107580484\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 28\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9612204754675386\t\tValidation metric: 8.447952899951654\n",
      "Train loss: 485716.4542015171\t\tValidation loss: 206612.91158496615\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 29\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.961056952878471\t\tValidation metric: 8.447576246627035\n",
      "Train loss: 485702.00697116926\t\tValidation loss: 206609.72275465904\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 30\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9609053204868405\t\tValidation metric: 8.447208086115495\n",
      "Train loss: 485688.7625939533\t\tValidation loss: 206606.73996952924\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 31\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9607650077108385\t\tValidation metric: 8.446850040163138\n",
      "Train loss: 485676.6499991122\t\tValidation loss: 206603.95912947995\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 32\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9606354384268294\t\tValidation metric: 8.446503578172504\n",
      "Train loss: 485665.5993459635\t\tValidation loss: 206601.37642981228\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 33\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9605160310064678\t\tValidation metric: 8.446169982236974\n",
      "Train loss: 485655.54209513223\t\tValidation loss: 206598.98809937114\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 34\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.960406201641082\t\tValidation metric: 8.445850323627349\n",
      "Train loss: 485646.4112817904\t\tValidation loss: 206596.79015096356\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 35\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.960305369133775\t\tValidation metric: 8.445545450483037\n",
      "Train loss: 485638.1418610851\t\tValidation loss: 206594.77817669412\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 36\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.960212960014803\t\tValidation metric: 8.445255985663628\n",
      "Train loss: 485630.6710477892\t\tValidation loss: 206592.94720405652\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 37\t-------|\n",
      "+--------\t----------\t-------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metric: 3.9601284133162276\t\tValidation metric: 8.44498233320636\n",
      "Train loss: 485623.9386083224\t\tValidation loss: 206591.29161640766\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 38\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9600511846680932\t\tValidation metric: 8.444724691582083\n",
      "Train loss: 485617.88708706107\t\tValidation loss: 206589.80513329094\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 39\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.9599807495878174\t\tValidation metric: 8.444483071898441\n",
      "Train loss: 485612.46196343534\t\tValidation loss: 206588.48084126896\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 40\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 3.959916605960102\t\tValidation metric: 8.444257319308113\n",
      "Train loss: 485607.6117444389\t\tValidation loss: 206587.31126370796\n"
     ]
    }
   ],
   "source": [
    "als = ALS()\n",
    "als.fit(train, test, n_epochs=40, metric_function=mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653496db",
   "metadata": {},
   "source": [
    "## Funk SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b7b49",
   "metadata": {},
   "source": [
    "Funk SVD has the same loss function as ALS but it is optimized by gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "74934b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunkSVD:\n",
    "    def __init__(self,\n",
    "                 hidden_size: int = 40,\n",
    "                 lambda_x: float = 10,\n",
    "                 lambda_y: float = 10,\n",
    "                 learning_rate: float = 3e-4):\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lambda_x = lambda_x\n",
    "        self.lambda_y = lambda_y\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def _compute_loss(self, ratings: np.ndarray):\n",
    "        nonzero_items = ratings.nonzero()\n",
    "        \n",
    "        main_term = np.sum((ratings[nonzero_items] - np.dot(self.X, self.Y.T)[nonzero_items]) ** 2)\n",
    "        user_regularization = self.lambda_x * np.sum(np.linalg.norm(self.X, axis=-1))\n",
    "        item_regularization = self.lambda_y * np.sum(np.linalg.norm(self.Y, axis=-1))\n",
    "        \n",
    "        return main_term + user_regularization + item_regularization\n",
    "        \n",
    "    def _step(self, ratings: np.ndarray):\n",
    "        X_lambda = np.linalg.inv(np.einsum(\"ij,ik->jk\", self.Y, self.Y) + self.lambda_x)\n",
    "        X_lambda = self.X.dot(X_lambda.T)\n",
    "        RY = ratings.dot(self.Y)\n",
    "        \n",
    "        Y_lambda = np.linalg.inv(np.einsum(\"ij,ik->jk\", self.X, self.X) + self.lambda_y)\n",
    "        Y_lambda = self.Y.dot(Y_lambda.T)\n",
    "        RTX = ratings.T.dot(self.X)\n",
    "\n",
    "        X_gradient = -RY + X_lambda\n",
    "        Y_gradient = -RTX + Y_lambda\n",
    "        \n",
    "        self.X -= self.learning_rate * X_gradient\n",
    "        self.Y -= self.learning_rate * Y_gradient\n",
    "        \n",
    "            \n",
    "    def _train_step(self, train_ratings: np.ndarray):\n",
    "        self._step(train_ratings)\n",
    "        loss = self._compute_loss(train_ratings)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    def _validation_step(self, val_ratings: np.ndarray):\n",
    "        loss = self._compute_loss(val_ratings)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "        \n",
    "    def fit(self, \n",
    "            train_ratings: np.ndarray, \n",
    "            val_ratings: np.ndarray, \n",
    "            max_epochs: int = 20,\n",
    "            metric_function = None,\n",
    "            verbose=True,\n",
    "            eps=1e-6):\n",
    "        \n",
    "        self.X = np.random.randn(ratings.shape[0], self.hidden_size)\n",
    "        self.Y = np.random.randn(ratings.shape[1], self.hidden_size)\n",
    "        \n",
    "        previous_predictions = None\n",
    "        current_predictions = None\n",
    "        for epoch in range(max_epochs):\n",
    "            train_loss = self._train_step(train_ratings)\n",
    "            val_loss = self._validation_step(val_ratings)\n",
    "            \n",
    "            print(f\"+--------\\t----------\\t-------+\")\n",
    "            print(f\"|--------\\t EPOCH: {epoch + 1}\\t-------|\")\n",
    "            print(f\"+--------\\t----------\\t-------+\")\n",
    "            previous_predictions = current_predictions\n",
    "            current_predictions = self.predict_all()\n",
    "            if metric_function is not None:\n",
    "                \n",
    "                \n",
    "                train_metric = metric_function(current_predictions, train_ratings)\n",
    "                val_metric = metric_function(current_predictions, val_ratings)\n",
    "                \n",
    "                print(f\"Train metric: {train_metric}\\t\\tValidation metric: {val_metric}\")\n",
    "            \n",
    "            print(f\"Train loss: {train_loss}\\t\\tValidation loss: {val_loss}\")\n",
    "            \n",
    "            if previous_predictions is not None and np.abs(current_predictions - previous_predictions < eps).all():\n",
    "                print(\"Criterion is reached. Leaving the training\")\n",
    "            \n",
    "    def predict(self, user: int, item: int):\n",
    "        return self.X[user].dot(self.Y[item])\n",
    "    \n",
    "    def predict_all(self):\n",
    "        return self.X.dot(self.Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "72a5ae5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 1\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.40117072444807\t\tValidation metric: 55.55683717495832\n",
      "Train loss: 5092145.307297968\t\tValidation loss: 688932.2493445638\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 2\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.39902920622601\t\tValidation metric: 55.55678228107275\n",
      "Train loss: 5091951.359906542\t\tValidation loss: 688931.7416091682\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 3\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.396888661634684\t\tValidation metric: 55.55672800742423\n",
      "Train loss: 5091757.5010127425\t\tValidation loss: 688931.2400384998\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 4\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.394749089614415\t\tValidation metric: 55.556674353395735\n",
      "Train loss: 5091563.730520598\t\tValidation loss: 688930.7446267421\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 5\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.39261048910651\t\tValidation metric: 55.55662131837057\n",
      "Train loss: 5091370.048334223\t\tValidation loss: 688930.2553680816\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 6\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.390472859053\t\tValidation metric: 55.556568901732376\n",
      "Train loss: 5091176.454357802\t\tValidation loss: 688929.772256708\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 7\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.38833619839685\t\tValidation metric: 55.55651710286518\n",
      "Train loss: 5090982.9484955985\t\tValidation loss: 688929.2952868147\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 8\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.38620050608192\t\tValidation metric: 55.556465921153304\n",
      "Train loss: 5090789.530651961\t\tValidation loss: 688928.8244525986\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 9\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.38406578105286\t\tValidation metric: 55.556415355981486\n",
      "Train loss: 5090596.200731312\t\tValidation loss: 688928.3597482599\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 10\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.38193202225525\t\tValidation metric: 55.556365406734756\n",
      "Train loss: 5090402.958638152\t\tValidation loss: 688927.9011680023\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 11\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.37979922863547\t\tValidation metric: 55.55631607279852\n",
      "Train loss: 5090209.804277058\t\tValidation loss: 688927.4487060327\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 12\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.37766739914078\t\tValidation metric: 55.556267353558496\n",
      "Train loss: 5090016.737552686\t\tValidation loss: 688927.0023565618\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 13\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.37553653271931\t\tValidation metric: 55.556219248400794\n",
      "Train loss: 5089823.758369772\t\tValidation loss: 688926.5621138035\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 14\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.373406628320055\t\tValidation metric: 55.55617175671184\n",
      "Train loss: 5089630.866633129\t\tValidation loss: 688926.127971975\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 15\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.37127768489283\t\tValidation metric: 55.55612487787838\n",
      "Train loss: 5089438.062247647\t\tValidation loss: 688925.6999252967\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 16\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.36914970138831\t\tValidation metric: 55.55607861128756\n",
      "Train loss: 5089245.345118291\t\tValidation loss: 688925.277967993\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 17\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.36702267675802\t\tValidation metric: 55.55603295632682\n",
      "Train loss: 5089052.715150103\t\tValidation loss: 688924.8620942913\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 18\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.36489660995436\t\tValidation metric: 55.55598791238395\n",
      "Train loss: 5088860.172248207\t\tValidation loss: 688924.452298422\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 19\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.362771499930545\t\tValidation metric: 55.5559434788471\n",
      "Train loss: 5088667.716317801\t\tValidation loss: 688924.0485746197\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 20\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.36064734564066\t\tValidation metric: 55.55589965510472\n",
      "Train loss: 5088475.347264159\t\tValidation loss: 688923.6509171213\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 21\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.35852414603961\t\tValidation metric: 55.55585644054565\n",
      "Train loss: 5088283.064992631\t\tValidation loss: 688923.2593201682\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 22\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.356401900083185\t\tValidation metric: 55.55581383455901\n",
      "Train loss: 5088090.869408647\t\tValidation loss: 688922.8737780042\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 23\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.35428060672798\t\tValidation metric: 55.555771836534305\n",
      "Train loss: 5087898.760417712\t\tValidation loss: 688922.4942848766\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 24\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.35216026493144\t\tValidation metric: 55.55573044586134\n",
      "Train loss: 5087706.737925405\t\tValidation loss: 688922.1208350364\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 25\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.35004087365185\t\tValidation metric: 55.55568966193029\n",
      "Train loss: 5087514.801837383\t\tValidation loss: 688921.7534227376\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 26\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.347922431848325\t\tValidation metric: 55.555649484131614\n",
      "Train loss: 5087322.95205938\t\tValidation loss: 688921.3920422375\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 27\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.34580493848085\t\tValidation metric: 55.55560991185615\n",
      "Train loss: 5087131.188497203\t\tValidation loss: 688921.0366877968\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 28\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.3436883925102\t\tValidation metric: 55.555570944495045\n",
      "Train loss: 5086939.511056741\t\tValidation loss: 688920.6873536794\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 29\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.34157279289802\t\tValidation metric: 55.5555325814398\n",
      "Train loss: 5086747.919643949\t\tValidation loss: 688920.3440341526\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 30\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.33945813860677\t\tValidation metric: 55.55549482208222\n",
      "Train loss: 5086556.414164866\t\tValidation loss: 688920.0067234868\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 31\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.33734442859973\t\tValidation metric: 55.555457665814416\n",
      "Train loss: 5086364.994525603\t\tValidation loss: 688919.6754159555\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 32\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.33523166184104\t\tValidation metric: 55.55542111202892\n",
      "Train loss: 5086173.660632347\t\tValidation loss: 688919.3501058362\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 33\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.33311983729564\t\tValidation metric: 55.55538516011849\n",
      "Train loss: 5085982.412391357\t\tValidation loss: 688919.0307874087\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 34\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.33100895392931\t\tValidation metric: 55.555349809476255\n",
      "Train loss: 5085791.249708973\t\tValidation loss: 688918.7174549565\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 35\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.32889901070866\t\tValidation metric: 55.555315059495705\n",
      "Train loss: 5085600.172491605\t\tValidation loss: 688918.4101027666\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 36\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.32679000660111\t\tValidation metric: 55.555280909570584\n",
      "Train loss: 5085409.18064574\t\tValidation loss: 688918.1087251285\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 37\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.324681940574905\t\tValidation metric: 55.555247359095006\n",
      "Train loss: 5085218.274077939\t\tValidation loss: 688917.8133163356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 38\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.322574811599125\t\tValidation metric: 55.5552144074634\n",
      "Train loss: 5085027.452694837\t\tValidation loss: 688917.523870684\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 39\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.320468618643645\t\tValidation metric: 55.55518205407053\n",
      "Train loss: 5084836.7164031435\t\tValidation loss: 688917.2403824736\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 40\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.31836336067921\t\tValidation metric: 55.55515029831146\n",
      "Train loss: 5084646.065109646\t\tValidation loss: 688916.9628460067\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 41\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.3162590366773\t\tValidation metric: 55.55511913958158\n",
      "Train loss: 5084455.498721198\t\tValidation loss: 688916.6912555895\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 42\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.314155645610285\t\tValidation metric: 55.555088577276614\n",
      "Train loss: 5084265.017144736\t\tValidation loss: 688916.4256055309\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 43\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.31205318645134\t\tValidation metric: 55.555058610792585\n",
      "Train loss: 5084074.620287267\t\tValidation loss: 688916.165890143\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 44\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.3099516581744\t\tValidation metric: 55.55502923952586\n",
      "Train loss: 5083884.308055867\t\tValidation loss: 688915.9121037414\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 45\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.30785105975425\t\tValidation metric: 55.5550004628731\n",
      "Train loss: 5083694.080357693\t\tValidation loss: 688915.6642406448\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 46\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.30575139016649\t\tValidation metric: 55.55497228023133\n",
      "Train loss: 5083503.937099973\t\tValidation loss: 688915.4222951746\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 47\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.30365264838752\t\tValidation metric: 55.55494469099781\n",
      "Train loss: 5083313.878190003\t\tValidation loss: 688915.1862616556\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 48\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.30155483339454\t\tValidation metric: 55.55491769457019\n",
      "Train loss: 5083123.903535163\t\tValidation loss: 688914.956134416\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 49\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.29945794416556\t\tValidation metric: 55.55489129034641\n",
      "Train loss: 5082934.013042895\t\tValidation loss: 688914.7319077869\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 50\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.29736197967943\t\tValidation metric: 55.5548654777247\n",
      "Train loss: 5082744.206620725\t\tValidation loss: 688914.5135761021\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 51\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.295266938915745\t\tValidation metric: 55.554840256103645\n",
      "Train loss: 5082554.484176241\t\tValidation loss: 688914.3011336992\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 52\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.29317282085492\t\tValidation metric: 55.55481562488212\n",
      "Train loss: 5082364.845617111\t\tValidation loss: 688914.0945749186\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 53\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.29107962447821\t\tValidation metric: 55.5547915834593\n",
      "Train loss: 5082175.290851073\t\tValidation loss: 688913.8938941038\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 54\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.28898734876762\t\tValidation metric: 55.554768131234695\n",
      "Train loss: 5081985.819785941\t\tValidation loss: 688913.6990856011\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 55\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.28689599270595\t\tValidation metric: 55.55474526760813\n",
      "Train loss: 5081796.432329594\t\tValidation loss: 688913.5101437606\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 56\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.28480555527687\t\tValidation metric: 55.5547229919797\n",
      "Train loss: 5081607.128389992\t\tValidation loss: 688913.3270629344\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 57\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.28271603546476\t\tValidation metric: 55.55470130374986\n",
      "Train loss: 5081417.907875161\t\tValidation loss: 688913.1498374789\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 58\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.280627432254825\t\tValidation metric: 55.554680202319325\n",
      "Train loss: 5081228.770693201\t\tValidation loss: 688912.9784617525\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 59\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.278539744633086\t\tValidation metric: 55.55465968708914\n",
      "Train loss: 5081039.716752286\t\tValidation loss: 688912.8129301172\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 60\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.27645297158634\t\tValidation metric: 55.55463975746066\n",
      "Train loss: 5080850.745960658\t\tValidation loss: 688912.653236938\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 61\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.274367112102134\t\tValidation metric: 55.55462041283555\n",
      "Train loss: 5080661.858226634\t\tValidation loss: 688912.4993765826\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 62\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.272282165168875\t\tValidation metric: 55.55460165261575\n",
      "Train loss: 5080473.053458601\t\tValidation loss: 688912.3513434223\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 63\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.2701981297757\t\tValidation metric: 55.55458347620354\n",
      "Train loss: 5080284.331565017\t\tValidation loss: 688912.2091318308\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 64\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.268115004912545\t\tValidation metric: 55.554565883001466\n",
      "Train loss: 5080095.692454411\t\tValidation loss: 688912.0727361853\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 65\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.26603278957018\t\tValidation metric: 55.55454887241242\n",
      "Train loss: 5079907.136035387\t\tValidation loss: 688911.9421508656\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 66\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.263951482740076\t\tValidation metric: 55.55453244383955\n",
      "Train loss: 5079718.662216617\t\tValidation loss: 688911.8173702547\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 67\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.26187108341454\t\tValidation metric: 55.55451659668635\n",
      "Train loss: 5079530.270906841\t\tValidation loss: 688911.6983887387\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 68\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.25979159058667\t\tValidation metric: 55.55450133035657\n",
      "Train loss: 5079341.962014878\t\tValidation loss: 688911.5852007065\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 69\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.257713003250295\t\tValidation metric: 55.55448664425428\n",
      "Train loss: 5079153.735449612\t\tValidation loss: 688911.4778005497\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 70\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.25563532040005\t\tValidation metric: 55.55447253778387\n",
      "Train loss: 5078965.591119994\t\tValidation loss: 688911.3761826638\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 71\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.25355854103135\t\tValidation metric: 55.55445901034997\n",
      "Train loss: 5078777.528935056\t\tValidation loss: 688911.2803414462\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 72\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.251482664140376\t\tValidation metric: 55.55444606135758\n",
      "Train loss: 5078589.548803889\t\tValidation loss: 688911.1902712978\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 73\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.2494076887241\t\tValidation metric: 55.55443369021192\n",
      "Train loss: 5078401.650635665\t\tValidation loss: 688911.1059666221\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 74\t-------|\n",
      "+--------\t----------\t-------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metric: 54.24733361378024\t\tValidation metric: 55.554421896318566\n",
      "Train loss: 5078213.834339618\t\tValidation loss: 688911.027421826\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 75\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.2452604383073\t\tValidation metric: 55.55441067908336\n",
      "Train loss: 5078026.099825055\t\tValidation loss: 688910.9546313193\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 76\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.243188161304566\t\tValidation metric: 55.554400037912444\n",
      "Train loss: 5077838.447001354\t\tValidation loss: 688910.887589514\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 77\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.24111678177208\t\tValidation metric: 55.55438997221225\n",
      "Train loss: 5077650.875777962\t\tValidation loss: 688910.826290826\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 78\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.23904629871063\t\tValidation metric: 55.5543804813895\n",
      "Train loss: 5077463.3860643925\t\tValidation loss: 688910.7707296732\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 79\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.23697671112181\t\tValidation metric: 55.55437156485121\n",
      "Train loss: 5077275.9777702335\t\tValidation loss: 688910.720900477\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 80\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.234908018007985\t\tValidation metric: 55.55436322200469\n",
      "Train loss: 5077088.650805141\t\tValidation loss: 688910.6767976616\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 81\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.23284021837224\t\tValidation metric: 55.554355452257525\n",
      "Train loss: 5076901.405078839\t\tValidation loss: 688910.6384156537\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 82\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.23077331121842\t\tValidation metric: 55.55434825501762\n",
      "Train loss: 5076714.24050112\t\tValidation loss: 688910.6057488836\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 83\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.228707295551196\t\tValidation metric: 55.55434162969314\n",
      "Train loss: 5076527.156981849\t\tValidation loss: 688910.5787917837\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 84\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.22664217037593\t\tValidation metric: 55.554335575692534\n",
      "Train loss: 5076340.1544309575\t\tValidation loss: 688910.5575387896\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 85\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.22457793469879\t\tValidation metric: 55.554330092424564\n",
      "Train loss: 5076153.232758446\t\tValidation loss: 688910.54198434\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 86\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.222514587526696\t\tValidation metric: 55.55432517929825\n",
      "Train loss: 5075966.391874386\t\tValidation loss: 688910.5321228759\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 87\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.22045212786724\t\tValidation metric: 55.554320835722926\n",
      "Train loss: 5075779.631688911\t\tValidation loss: 688910.5279488415\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 88\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.21839055472892\t\tValidation metric: 55.55431706110818\n",
      "Train loss: 5075592.952112232\t\tValidation loss: 688910.5294566839\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 89\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.21632986712087\t\tValidation metric: 55.55431385486389\n",
      "Train loss: 5075406.353054623\t\tValidation loss: 688910.5366408527\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 90\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.214270064053004\t\tValidation metric: 55.554311216400244\n",
      "Train loss: 5075219.834426427\t\tValidation loss: 688910.5494958006\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 91\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.21221114453602\t\tValidation metric: 55.55430914512768\n",
      "Train loss: 5075033.396138057\t\tValidation loss: 688910.5680159831\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 92\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.210153107581334\t\tValidation metric: 55.55430764045693\n",
      "Train loss: 5074847.03809999\t\tValidation loss: 688910.5921958582\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 93\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.20809595220111\t\tValidation metric: 55.55430670179899\n",
      "Train loss: 5074660.760222777\t\tValidation loss: 688910.622029887\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 94\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.20603967740826\t\tValidation metric: 55.5543063285652\n",
      "Train loss: 5074474.562417031\t\tValidation loss: 688910.6575125335\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 95\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.2039842822165\t\tValidation metric: 55.55430652016706\n",
      "Train loss: 5074288.444593437\t\tValidation loss: 688910.6986382639\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 96\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.20192976564018\t\tValidation metric: 55.554307276016466\n",
      "Train loss: 5074102.4066627445\t\tValidation loss: 688910.7454015478\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 97\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.19987612669449\t\tValidation metric: 55.55430859552551\n",
      "Train loss: 5073916.448535772\t\tValidation loss: 688910.7977968571\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 98\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.19782336439532\t\tValidation metric: 55.55431047810663\n",
      "Train loss: 5073730.570123405\t\tValidation loss: 688910.855818667\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 99\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.19577147775931\t\tValidation metric: 55.55431292317248\n",
      "Train loss: 5073544.771336599\t\tValidation loss: 688910.9194614548\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 100\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.1937204658038\t\tValidation metric: 55.55431593013601\n",
      "Train loss: 5073359.052086368\t\tValidation loss: 688910.9887197012\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 101\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.191670327546944\t\tValidation metric: 55.55431949841045\n",
      "Train loss: 5073173.412283805\t\tValidation loss: 688911.0635878887\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 102\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.1896210620076\t\tValidation metric: 55.55432362740929\n",
      "Train loss: 5072987.851840063\t\tValidation loss: 688911.1440605037\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 103\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.18757266820535\t\tValidation metric: 55.554328316546325\n",
      "Train loss: 5072802.3706663605\t\tValidation loss: 688911.2301320347\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 104\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.18552514516049\t\tValidation metric: 55.55433356523557\n",
      "Train loss: 5072616.968673987\t\tValidation loss: 688911.3217969728\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 105\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.18347849189412\t\tValidation metric: 55.554339372891356\n",
      "Train loss: 5072431.645774297\t\tValidation loss: 688911.4190498121\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 106\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.18143270742798\t\tValidation metric: 55.55434573892826\n",
      "Train loss: 5072246.401878707\t\tValidation loss: 688911.5218850491\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 107\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.179387790784645\t\tValidation metric: 55.55435266276114\n",
      "Train loss: 5072061.236898711\t\tValidation loss: 688911.6302971832\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 108\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.17734374098733\t\tValidation metric: 55.55436014380512\n",
      "Train loss: 5071876.150745857\t\tValidation loss: 688911.7442807166\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 109\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.17530055706003\t\tValidation metric: 55.55436818147559\n",
      "Train loss: 5071691.143331766\t\tValidation loss: 688911.8638301541\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 110\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.173258238027444\t\tValidation metric: 55.5543767751882\n",
      "Train loss: 5071506.214568123\t\tValidation loss: 688911.9889400029\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 111\t-------|\n",
      "+--------\t----------\t-------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metric: 54.171216782914996\t\tValidation metric: 55.55438592435889\n",
      "Train loss: 5071321.36436668\t\tValidation loss: 688912.1196047731\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 112\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.16917619074887\t\tValidation metric: 55.554395628403846\n",
      "Train loss: 5071136.592639254\t\tValidation loss: 688912.2558189775\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 113\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.16713646055592\t\tValidation metric: 55.55440588673952\n",
      "Train loss: 5070951.899297727\t\tValidation loss: 688912.3975771316\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 114\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.165097591363775\t\tValidation metric: 55.55441669878263\n",
      "Train loss: 5070767.284254051\t\tValidation loss: 688912.5448737533\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 115\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.163059582200745\t\tValidation metric: 55.55442806395016\n",
      "Train loss: 5070582.747420236\t\tValidation loss: 688912.6977033633\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 116\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.16102243209587\t\tValidation metric: 55.55443998165936\n",
      "Train loss: 5070398.28870836\t\tValidation loss: 688912.8560604848\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 117\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.15898614007892\t\tValidation metric: 55.554452451327734\n",
      "Train loss: 5070213.908030571\t\tValidation loss: 688913.0199396438\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 118\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.15695070518038\t\tValidation metric: 55.55446547237306\n",
      "Train loss: 5070029.605299077\t\tValidation loss: 688913.1893353689\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 119\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.15491612643146\t\tValidation metric: 55.554479044213366\n",
      "Train loss: 5069845.380426156\t\tValidation loss: 688913.3642421911\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 120\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.15288240286404\t\tValidation metric: 55.554493166266916\n",
      "Train loss: 5069661.233324143\t\tValidation loss: 688913.5446546442\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 121\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.15084953351079\t\tValidation metric: 55.55450783795229\n",
      "Train loss: 5069477.163905446\t\tValidation loss: 688913.7305672646\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 122\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.14881751740502\t\tValidation metric: 55.5545230586883\n",
      "Train loss: 5069293.172082533\t\tValidation loss: 688913.9219745912\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 123\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.146786353580794\t\tValidation metric: 55.554538827893964\n",
      "Train loss: 5069109.257767938\t\tValidation loss: 688914.1188711653\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 124\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.14475604107286\t\tValidation metric: 55.55455514498866\n",
      "Train loss: 5068925.420874257\t\tValidation loss: 688914.3212515314\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 125\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.1427265789167\t\tValidation metric: 55.554572009391926\n",
      "Train loss: 5068741.661314155\t\tValidation loss: 688914.5291102359\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 126\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.14069796614851\t\tValidation metric: 55.55458942052362\n",
      "Train loss: 5068557.979000361\t\tValidation loss: 688914.7424418279\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 127\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.138670201805155\t\tValidation metric: 55.554607377803805\n",
      "Train loss: 5068374.373845662\t\tValidation loss: 688914.9612408595\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 128\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.13664328492423\t\tValidation metric: 55.554625880652814\n",
      "Train loss: 5068190.845762916\t\tValidation loss: 688915.1855018843\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 129\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.13461721454405\t\tValidation metric: 55.55464492849128\n",
      "Train loss: 5068007.394665042\t\tValidation loss: 688915.41521946\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 130\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.1325919897036\t\tValidation metric: 55.55466452074001\n",
      "Train loss: 5067824.020465022\t\tValidation loss: 688915.6503881454\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 131\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.13056760944258\t\tValidation metric: 55.554684656820136\n",
      "Train loss: 5067640.723075903\t\tValidation loss: 688915.8910025026\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 132\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.12854407280138\t\tValidation metric: 55.554705336152985\n",
      "Train loss: 5067457.502410795\t\tValidation loss: 688916.1370570962\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 133\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.126521378821145\t\tValidation metric: 55.554726558160134\n",
      "Train loss: 5067274.358382873\t\tValidation loss: 688916.3885464926\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 134\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.124499526543644\t\tValidation metric: 55.55474832226348\n",
      "Train loss: 5067091.290905375\t\tValidation loss: 688916.6454652618\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 135\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.12247851501138\t\tValidation metric: 55.55477062788507\n",
      "Train loss: 5066908.2998916\t\tValidation loss: 688916.9078079752\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 136\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.12045834326755\t\tValidation metric: 55.55479347444728\n",
      "Train loss: 5066725.385254912\t\tValidation loss: 688917.1755692076\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 137\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.11843901035606\t\tValidation metric: 55.5548168613727\n",
      "Train loss: 5066542.546908741\t\tValidation loss: 688917.4487435359\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 138\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.11642051532148\t\tValidation metric: 55.554840788084135\n",
      "Train loss: 5066359.784766572\t\tValidation loss: 688917.727325539\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 139\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.11440285720908\t\tValidation metric: 55.5548652540047\n",
      "Train loss: 5066177.098741962\t\tValidation loss: 688918.0113097993\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 140\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.112386035064844\t\tValidation metric: 55.554890258557705\n",
      "Train loss: 5065994.488748524\t\tValidation loss: 688918.3006909008\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 141\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.110370047935426\t\tValidation metric: 55.55491580116673\n",
      "Train loss: 5065811.95469994\t\tValidation loss: 688918.5954634303\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 142\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.108354894868164\t\tValidation metric: 55.554941881255594\n",
      "Train loss: 5065629.496509947\t\tValidation loss: 688918.8956219772\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 143\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.106340574911115\t\tValidation metric: 55.55496849824835\n",
      "Train loss: 5065447.114092351\t\tValidation loss: 688919.2011611329\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 144\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.10432708711298\t\tValidation metric: 55.55499565156928\n",
      "Train loss: 5065264.807361016\t\tValidation loss: 688919.5120754912\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 145\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.102314430523194\t\tValidation metric: 55.55502334064295\n",
      "Train loss: 5065082.576229872\t\tValidation loss: 688919.8283596493\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 146\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.10030260419182\t\tValidation metric: 55.55505156489413\n",
      "Train loss: 5064900.420612907\t\tValidation loss: 688920.1500082057\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 147\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.09829160716966\t\tValidation metric: 55.55508032374782\n",
      "Train loss: 5064718.340424174\t\tValidation loss: 688920.4770157617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 148\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.09628143850817\t\tValidation metric: 55.55510961662932\n",
      "Train loss: 5064536.335577792\t\tValidation loss: 688920.8093769213\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 149\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.094272097259484\t\tValidation metric: 55.555139442964105\n",
      "Train loss: 5064354.4059879305\t\tValidation loss: 688921.1470862903\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 150\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.09226358247641\t\tValidation metric: 55.55516980217791\n",
      "Train loss: 5064172.5515688285\t\tValidation loss: 688921.4901384774\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 151\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.090255893212486\t\tValidation metric: 55.55520069369671\n",
      "Train loss: 5063990.772234789\t\tValidation loss: 688921.8385280938\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 152\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.08824902852186\t\tValidation metric: 55.55523211694671\n",
      "Train loss: 5063809.067900169\t\tValidation loss: 688922.1922497525\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 153\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.086242987459386\t\tValidation metric: 55.55526407135435\n",
      "Train loss: 5063627.438479394\t\tValidation loss: 688922.5512980688\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 154\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.084237769080595\t\tValidation metric: 55.555296556346335\n",
      "Train loss: 5063445.883886945\t\tValidation loss: 688922.9156676616\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 155\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.08223337244171\t\tValidation metric: 55.55532957134953\n",
      "Train loss: 5063264.40403737\t\tValidation loss: 688923.2853531507\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 156\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.08022979659961\t\tValidation metric: 55.55536311579112\n",
      "Train loss: 5063082.9988452755\t\tValidation loss: 688923.6603491589\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 157\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.0782270406118\t\tValidation metric: 55.55539718909846\n",
      "Train loss: 5062901.668225325\t\tValidation loss: 688924.0406503115\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 158\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.07622510353656\t\tValidation metric: 55.55543179069916\n",
      "Train loss: 5062720.412092248\t\tValidation loss: 688924.4262512358\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 159\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.07422398443274\t\tValidation metric: 55.55546692002108\n",
      "Train loss: 5062539.230360836\t\tValidation loss: 688924.8171465616\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 160\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.072223682359905\t\tValidation metric: 55.555502576492266\n",
      "Train loss: 5062358.122945935\t\tValidation loss: 688925.2133309209\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 161\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.07022419637829\t\tValidation metric: 55.55553875954104\n",
      "Train loss: 5062177.089762458\t\tValidation loss: 688925.6147989482\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 162\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.06822552554879\t\tValidation metric: 55.55557546859591\n",
      "Train loss: 5061996.130725375\t\tValidation loss: 688926.0215452801\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 163\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.06622766893297\t\tValidation metric: 55.55561270308564\n",
      "Train loss: 5061815.245749717\t\tValidation loss: 688926.4335645557\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 164\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.06423062559304\t\tValidation metric: 55.55565046243921\n",
      "Train loss: 5061634.434750576\t\tValidation loss: 688926.8508514164\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 165\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.06223439459188\t\tValidation metric: 55.55568874608585\n",
      "Train loss: 5061453.697643102\t\tValidation loss: 688927.2734005058\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 166\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.06023897499307\t\tValidation metric: 55.55572755345497\n",
      "Train loss: 5061273.034342512\t\tValidation loss: 688927.7012064696\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 167\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.05824436586079\t\tValidation metric: 55.55576688397624\n",
      "Train loss: 5061092.444764072\t\tValidation loss: 688928.134263956\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 168\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.05625056625991\t\tValidation metric: 55.55580673707956\n",
      "Train loss: 5060911.928823115\t\tValidation loss: 688928.5725676155\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 169\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.05425757525596\t\tValidation metric: 55.55584711219502\n",
      "Train loss: 5060731.486435035\t\tValidation loss: 688929.0161121009\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 170\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.05226539191515\t\tValidation metric: 55.55588800875295\n",
      "Train loss: 5060551.117515282\t\tValidation loss: 688929.464892067\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 171\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.0502740153043\t\tValidation metric: 55.55592942618394\n",
      "Train loss: 5060370.821979368\t\tValidation loss: 688929.9189021713\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 172\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.04828344449091\t\tValidation metric: 55.55597136391873\n",
      "Train loss: 5060190.599742861\t\tValidation loss: 688930.3781370729\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 173\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.04629367854313\t\tValidation metric: 55.556013821388326\n",
      "Train loss: 5060010.450721392\t\tValidation loss: 688930.8425914337\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 174\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.04430471652977\t\tValidation metric: 55.55605679802396\n",
      "Train loss: 5059830.374830653\t\tValidation loss: 688931.3122599174\n",
      "+--------\t----------\t-------+\n",
      "|--------\t EPOCH: 175\t-------|\n",
      "+--------\t----------\t-------+\n",
      "Train metric: 54.0423165575203\t\tValidation metric: 55.55610029325705\n",
      "Train loss: 5059650.37198639\t\tValidation loss: 688931.7871371905\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2248\\3300574865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfunk_svd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunkSVD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfunk_svd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2248\\2452461520.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_ratings, val_ratings, max_epochs, metric_function, verbose, eps)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Train loss: {train_loss}\\t\\tValidation loss: {val_loss}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mprevious_predictions\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_predictions\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mprevious_predictions\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Criterion is reached. Leaving the training\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "funk_svd = FunkSVD(learning_rate=1e-6)\n",
    "funk_svd.fit(train, test, max_epochs=1000, metric_function=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f86698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
